{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":65711,"databundleVersionId":7405009,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier, Pool\nfrom catboost.utils import eval_metric\nfrom sklearn.metrics import roc_auc_score\nimport os\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import ttest_ind, zscore\nfrom statsmodels.stats.weightstats import ztest\nfrom scipy.stats import chi2_contingency","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T20:50:09.759130Z","iopub.execute_input":"2024-11-01T20:50:09.759610Z","iopub.status.idle":"2024-11-01T20:50:09.775531Z","shell.execute_reply.started":"2024-11-01T20:50:09.759566Z","shell.execute_reply":"2024-11-01T20:50:09.773597Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:09.778794Z","iopub.execute_input":"2024-11-01T20:50:09.779740Z","iopub.status.idle":"2024-11-01T20:50:09.792411Z","shell.execute_reply.started":"2024-11-01T20:50:09.779679Z","shell.execute_reply":"2024-11-01T20:50:09.791189Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s4e1/sample_submission.csv\n/kaggle/input/playground-series-s4e1/train.csv\n/kaggle/input/playground-series-s4e1/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/playground-series-s4e1/test.csv')\ndf_train = pd.read_csv('/kaggle/input/playground-series-s4e1/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:09.794594Z","iopub.execute_input":"2024-11-01T20:50:09.795304Z","iopub.status.idle":"2024-11-01T20:50:10.333852Z","shell.execute_reply.started":"2024-11-01T20:50:09.795257Z","shell.execute_reply":"2024-11-01T20:50:10.332590Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"print('----------------')\nprint(df_test.head())\nprint('\\n')\nprint('----------------')\nprint(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:10.335374Z","iopub.execute_input":"2024-11-01T20:50:10.335769Z","iopub.status.idle":"2024-11-01T20:50:10.362150Z","shell.execute_reply.started":"2024-11-01T20:50:10.335727Z","shell.execute_reply":"2024-11-01T20:50:10.360630Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"----------------\n       id  CustomerId    Surname  CreditScore Geography  Gender   Age  Tenure  \\\n0  165034    15773898   Lucchese          586    France  Female  23.0       2   \n1  165035    15782418       Nott          683    France  Female  46.0       2   \n2  165036    15807120         K?          656    France  Female  34.0       7   \n3  165037    15808905  O'Donnell          681    France    Male  36.0       8   \n4  165038    15607314    Higgins          752   Germany    Male  38.0      10   \n\n     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n0       0.00              2        0.0             1.0        160976.75  \n1       0.00              1        1.0             0.0         72549.27  \n2       0.00              2        1.0             0.0        138882.09  \n3       0.00              1        1.0             0.0        113931.57  \n4  121263.62              1        1.0             0.0        139431.00  \n\n\n----------------\n            id  CustomerId         Surname  CreditScore Geography  Gender  \\\n0            0    15674932  Okwudilichukwu          668    France    Male   \n1            1    15749177   Okwudiliolisa          627    France    Male   \n2            2    15694510           Hsueh          678    France    Male   \n3            3    15741417             Kao          581    France    Male   \n4            4    15766172       Chiemenam          716     Spain    Male   \n...        ...         ...             ...          ...       ...     ...   \n165029  165029    15667085            Meng          667     Spain  Female   \n165030  165030    15665521       Okechukwu          792    France    Male   \n165031  165031    15664752            Hsia          565    France    Male   \n165032  165032    15689614          Hsiung          554     Spain  Female   \n165033  165033    15732798         Ulyanov          850    France    Male   \n\n         Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n0       33.0       3       0.00              2        1.0             0.0   \n1       33.0       1       0.00              2        1.0             1.0   \n2       40.0      10       0.00              2        1.0             0.0   \n3       34.0       2  148882.54              1        1.0             1.0   \n4       33.0       5       0.00              2        1.0             1.0   \n...      ...     ...        ...            ...        ...             ...   \n165029  33.0       2       0.00              1        1.0             1.0   \n165030  35.0       3       0.00              1        0.0             0.0   \n165031  31.0       5       0.00              1        1.0             1.0   \n165032  30.0       7  161533.00              1        0.0             1.0   \n165033  31.0       1       0.00              1        1.0             0.0   \n\n        EstimatedSalary  Exited  \n0             181449.97       0  \n1              49503.50       0  \n2             184866.69       0  \n3              84560.88       0  \n4              15068.83       0  \n...                 ...     ...  \n165029        131834.75       0  \n165030        131834.45       0  \n165031        127429.56       0  \n165032         71173.03       0  \n165033         61581.79       1  \n\n[165034 rows x 14 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef add_nulls(df, fraction=0.1):\n    df = df.copy()\n    num_cells = df.shape[0] * df.shape[1]\n    num_nulls = int(num_cells * fraction)\n    rows = np.random.randint(0, df.shape[0], num_nulls)\n    cols = np.random.randint(0, df.shape[1], num_nulls)\n\n    for row, col in zip(rows, cols):\n        df.iat[row, col] = np.nan\n\n    return df\n\ndef add_duplicates(df, fraction=0.1):\n    df = df.copy()\n    num_rows = int(len(df) * fraction)\n    duplicate_rows = df.sample(num_rows, replace=True)\n    return pd.concat([df, duplicate_rows], ignore_index=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:10.365698Z","iopub.execute_input":"2024-11-01T20:50:10.366255Z","iopub.status.idle":"2024-11-01T20:50:10.377280Z","shell.execute_reply.started":"2024-11-01T20:50:10.366199Z","shell.execute_reply":"2024-11-01T20:50:10.375974Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"df_test = add_nulls(df_test)\ndf_test = add_duplicates(df_test)\n\ndf_train = add_nulls(df_train)\ndf_train = add_duplicates(df_train)\n\n# Save the modified DataFrames to CSV files\ndf_train.to_csv(\"train_data_modified.csv\", index=False)\ndf_test.to_csv(\"test_data_modified.csv\", index=False)\n\nprint(\"Datasets with nulls and duplicates have been saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:10.378657Z","iopub.execute_input":"2024-11-01T20:50:10.379085Z","iopub.status.idle":"2024-11-01T20:50:23.260698Z","shell.execute_reply.started":"2024-11-01T20:50:10.379011Z","shell.execute_reply":"2024-11-01T20:50:23.259218Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Datasets with nulls and duplicates have been saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_null = df_train.isnull().sum().sum()\n\ntest_null = df_test.isnull().sum().sum()\n\nprint(f'Null Count in Train: {train_null}')\nprint(f'Null Count in Test: {test_null}')","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:23.262740Z","iopub.execute_input":"2024-11-01T20:50:23.263171Z","iopub.status.idle":"2024-11-01T20:50:23.372910Z","shell.execute_reply.started":"2024-11-01T20:50:23.263129Z","shell.execute_reply":"2024-11-01T20:50:23.371773Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Null Count in Train: 241870\nNull Count in Test: 149826\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_duplicates = df_train.duplicated().sum()\ntest_duplicates = df_test.duplicated().sum()\nprint(f\"Number of duplicate rows in train_data: {train_duplicates}\")\nprint(f\"Number of duplicate rows in test_data: {test_duplicates}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:23.374434Z","iopub.execute_input":"2024-11-01T20:50:23.374806Z","iopub.status.idle":"2024-11-01T20:50:23.679260Z","shell.execute_reply.started":"2024-11-01T20:50:23.374759Z","shell.execute_reply":"2024-11-01T20:50:23.678091Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Number of duplicate rows in train_data: 16503\nNumber of duplicate rows in test_data: 11002\n","output_type":"stream"}]},{"cell_type":"code","source":"train_null = df_train.isnull().sum().sum()\n\ntest_null = df_test.isnull().sum().sum()\n\nprint(f'Null Count in Train: {train_null}')\nprint(f'Null Count in Test: {test_null}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:23.687597Z","iopub.execute_input":"2024-11-01T20:50:23.688084Z","iopub.status.idle":"2024-11-01T20:50:23.801304Z","shell.execute_reply.started":"2024-11-01T20:50:23.688003Z","shell.execute_reply":"2024-11-01T20:50:23.800117Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Null Count in Train: 241870\nNull Count in Test: 149826\n","output_type":"stream"}]},{"cell_type":"code","source":"train_duplicates = df_train.duplicated().sum()\ntest_duplicates = df_test.duplicated().sum()\n\nprint(f\"Number of duplicate rows in train_data: {train_duplicates}\")\nprint(f\"Number of duplicate rows in test_data: {test_duplicates}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:23.805477Z","iopub.execute_input":"2024-11-01T20:50:23.805868Z","iopub.status.idle":"2024-11-01T20:50:24.093971Z","shell.execute_reply.started":"2024-11-01T20:50:23.805829Z","shell.execute_reply":"2024-11-01T20:50:24.092722Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Number of duplicate rows in train_data: 16503\nNumber of duplicate rows in test_data: 11002\n","output_type":"stream"}]},{"cell_type":"code","source":"num_col = df_train.select_dtypes(include=['number']).columns\nprint(num_col)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:24.095359Z","iopub.execute_input":"2024-11-01T20:50:24.095714Z","iopub.status.idle":"2024-11-01T20:50:24.116940Z","shell.execute_reply.started":"2024-11-01T20:50:24.095679Z","shell.execute_reply":"2024-11-01T20:50:24.115854Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Index(['id', 'CustomerId', 'CreditScore', 'Age', 'Tenure', 'Balance',\n       'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary',\n       'Exited'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"from statsmodels.stats.weightstats import ztest\n\n# Extract credit score data for each gender and drop NaNs\nmale_credit_score = df_train[df_train['Gender'] == 'Male']['CreditScore'].dropna()\nfemale_credit_score = df_train[df_train['Gender'] == 'Female']['CreditScore'].dropna()\n\n# Check for empty groups or zero variance\nif len(male_credit_score) == 0 or len(female_credit_score) == 0:\n    print(\"One of the groups has no data.\")\nelif male_credit_score.std() == 0 or female_credit_score.std() == 0:\n    print(\"One of the groups has zero variance.\")\nelse:\n    # Perform Z-test\n    z_stat, p_value = ztest(male_credit_score, female_credit_score)\n\n    print(f\"Z-test Statistic: {z_stat}\")\n    print(f\"P-value: {p_value}\")\n\n    # Interpretation\n    if p_value < 0.05:\n        print(\"Reject the null hypothesis: There is a significant difference in CreditScore between males and females.\")\n    else:\n        print(\"Fail to reject the null hypothesis: No significant difference in CreditScore between males and females.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.189032Z","iopub.execute_input":"2024-11-01T20:50:32.189964Z","iopub.status.idle":"2024-11-01T20:50:32.291581Z","shell.execute_reply.started":"2024-11-01T20:50:32.189909Z","shell.execute_reply":"2024-11-01T20:50:32.290335Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Z-test Statistic: 0.346324847272583\nP-value: 0.7290985972603619\nFail to reject the null hypothesis: No significant difference in CreditScore between males and females.\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\n# Extract balances for each country and remove NaNs\nfrance_balance = df_train[df_train['Geography'] == 'France']['Balance'].dropna()\ngermany_balance = df_train[df_train['Geography'] == 'Germany']['Balance'].dropna()\n\n# Check for empty groups or zero variance\nif len(france_balance) == 0 or len(germany_balance) == 0:\n    print(\"One of the groups has no data.\")\nelif france_balance.std() == 0 or germany_balance.std() == 0:\n    print(\"One of the groups has zero variance.\")\nelse:\n    # Perform T-test\n    t_stat, p_value = ttest_ind(france_balance, germany_balance, equal_var=False)\n\n    print(f\"T-test Statistic: {t_stat}\")\n    print(f\"P-value: {p_value}\")\n\n    # Interpretation\n    if p_value < 0.05:\n        print(\"Reject the null hypothesis: There is a significant difference in Balance between France and Germany.\")\n    else:\n        print(\"Fail to reject the null hypothesis: No significant difference in Balance between France and Germany.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.293007Z","iopub.execute_input":"2024-11-01T20:50:32.293411Z","iopub.status.idle":"2024-11-01T20:50:32.391934Z","shell.execute_reply.started":"2024-11-01T20:50:32.293371Z","shell.execute_reply":"2024-11-01T20:50:32.390636Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"T-test Statistic: -351.4492896889327\nP-value: 0.0\nReject the null hypothesis: There is a significant difference in Balance between France and Germany.\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\n# Extract balances for each country and remove NaNs\nfrance_balance = df_train[df_train['Geography'] == 'France']['Balance'].dropna()\nspain_balance = df_train[df_train['Geography'] == 'Spain']['Balance'].dropna()\n\n# Check for empty groups or zero variance\nif len(france_balance) == 0 or len(spain_balance) == 0:\n    print(\"One of the groups has no data.\")\nelif france_balance.std() == 0 or spain_balance.std() == 0:\n    print(\"One of the groups has zero variance.\")\nelse:\n    # Perform T-test\n    t_stat, p_value = ttest_ind(france_balance, spain_balance, equal_var=False)\n\n    print(f\"T-test Statistic: {t_stat}\")\n    print(f\"P-value: {p_value}\")\n\n    # Interpretation\n    if p_value < 0.05:\n        print(\"Reject the null hypothesis: There is a significant difference in Balance between France and Spain.\")\n    else:\n        print(\"Fail to reject the null hypothesis: No significant difference in Balance between France and Spain.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.393272Z","iopub.execute_input":"2024-11-01T20:50:32.393654Z","iopub.status.idle":"2024-11-01T20:50:32.490765Z","shell.execute_reply.started":"2024-11-01T20:50:32.393612Z","shell.execute_reply":"2024-11-01T20:50:32.489592Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"T-test Statistic: -7.385894520291346\nP-value: 1.5346201202565083e-13\nReject the null hypothesis: There is a significant difference in Balance between France and Spain.\n","output_type":"stream"}]},{"cell_type":"code","source":"from scipy.stats import ttest_ind\n\n# Extract balances for each country and remove NaNs\ngermany_balance = df_train[df_train['Geography'] == 'Germany']['Balance'].dropna()\nspain_balance = df_train[df_train['Geography'] == 'Spain']['Balance'].dropna()\n\n# Check for empty groups, zero variance, and data types\nif len(germany_balance) == 0 or len(spain_balance) == 0:\n    print(\"One of the groups has no data.\")\nelif germany_balance.std() == 0 or spain_balance.std() == 0:\n    print(\"One of the groups has zero variance.\")\nelif not pd.api.types.is_numeric_dtype(germany_balance) or not pd.api.types.is_numeric_dtype(spain_balance):\n    print(\"One of the groups contains non-numeric data.\")\nelse:\n    # Perform T-test\n    t_stat, p_value = ttest_ind(germany_balance, spain_balance, equal_var=False)\n\n    print(f\"T-test Statistic: {t_stat}\")\n    print(f\"P-value: {p_value}\")\n\n    # Interpretation\n    if p_value < 0.05:\n        print(\"Reject the null hypothesis: There is a significant difference in Balance between Germany and Spain.\")\n    else:\n        print(\"Fail to reject the null hypothesis: No significant difference in Balance between Germany and Spain.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.492103Z","iopub.execute_input":"2024-11-01T20:50:32.492468Z","iopub.status.idle":"2024-11-01T20:50:32.585331Z","shell.execute_reply.started":"2024-11-01T20:50:32.492429Z","shell.execute_reply":"2024-11-01T20:50:32.583828Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"T-test Statistic: 229.05496344878645\nP-value: 0.0\nReject the null hypothesis: There is a significant difference in Balance between Germany and Spain.\n","output_type":"stream"}]},{"cell_type":"code","source":"contingency_table = pd.crosstab(df_train['Gender'], df_train['Geography'])\nprint(contingency_table)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.587575Z","iopub.execute_input":"2024-11-01T20:50:32.588804Z","iopub.status.idle":"2024-11-01T20:50:32.684337Z","shell.execute_reply.started":"2024-11-01T20:50:32.588724Z","shell.execute_reply":"2024-11-01T20:50:32.683094Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Geography  France  Germany  Spain\nGender                           \nFemale      36076    14749  13917\nMale        48665    16378  18562\n","output_type":"stream"}]},{"cell_type":"code","source":"chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n\nprint(f\"Chi-squared Statistic: {chi2_stat}\")\nprint(f\"P-value: {p_value}\")\nprint(f\"Degrees of Freedom: {dof}\")\nprint(\"Expected Frequencies:\")\nprint(expected)\n\nif p_value < 0.05:\n    print(\"Reject the null hypothesis: There is a significant association between Gender and Geography.\")\nelse:\n    print(\"Fail to reject the null hypothesis: No significant association between Gender and Geography.\")","metadata":{"execution":{"iopub.status.busy":"2024-11-01T20:50:32.686079Z","iopub.execute_input":"2024-11-01T20:50:32.686524Z","iopub.status.idle":"2024-11-01T20:50:32.696032Z","shell.execute_reply.started":"2024-11-01T20:50:32.686481Z","shell.execute_reply":"2024-11-01T20:50:32.694697Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"Chi-squared Statistic: 224.8817450132571\nP-value: 1.4707861445919838e-49\nDegrees of Freedom: 2\nExpected Frequencies:\n[[36982.897005   13584.52974445 14174.57325055]\n [47758.102995   17542.47025555 18304.42674945]]\nReject the null hypothesis: There is a significant association between Gender and Geography.\n","output_type":"stream"}]}]}