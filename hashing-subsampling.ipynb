{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":65711,"databundleVersionId":7405009,"sourceType":"competition"},{"sourceId":9789868,"sourceType":"datasetVersion","datasetId":5998716}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import HashingVectorizer\n\ndef apply_feature_hashing(df, categorical_columns, n_features=5):\n    hasher = HashingVectorizer(n_features=n_features, norm=None, alternate_sign=False)\n    for col in categorical_columns:\n        # Ensure the column is treated as string\n        df[col] = df[col].astype(str)\n        # Apply feature hashing\n        hashed_features = hasher.transform(df[col]).toarray()\n        # Create hashed feature column names\n        hashed_columns = [f\"{col}_hash_{i}\" for i in range(n_features)]\n        hashed_df = pd.DataFrame(hashed_features, columns=hashed_columns, index=df.index)\n        # Replace the original column with hashed features\n        df = pd.concat([df.drop(columns=[col]), hashed_df], axis=1)\n    return df\n\ncategorical_columns = ['Surname', 'Geography', 'Gender']\n\n\nhashed_df = apply_feature_hashing(df, categorical_columns, n_features=5)\n\nprint(hashed_df.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T23:10:21.457033Z","iopub.execute_input":"2024-12-02T23:10:21.457653Z","iopub.status.idle":"2024-12-02T23:10:23.320015Z","shell.execute_reply.started":"2024-12-02T23:10:21.457608Z","shell.execute_reply":"2024-12-02T23:10:23.319133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load and preprocess data\ndf = pd.read_csv('/kaggle/input/complete-dataset/augmented_data.csv')\ndf = df.drop_duplicates()\n\ndef fill_missing_values(df):\n    # For numerical columns\n    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n    for col in numerical_cols:\n        df[col] = df[col].fillna(df[col].mean())\n    \n    # For categorical columns (including HasCrCard and IsActiveMember)\n    categorical_cols = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n    for col in categorical_cols:\n        df[col] = df[col].fillna(df[col].mode()[0])\n    \n    return df\n\ndf = fill_missing_values(df)\n\n# Drop unnecessary columns\ncolumns_to_drop = ['id', 'Surname', 'CustomerId']\ndf = df.drop(columns=columns_to_drop)\n\n# Convert HasCrCard and IsActiveMember to categorical\ndf['HasCrCard'] = df['HasCrCard'].astype('category')\ndf['IsActiveMember'] = df['IsActiveMember'].astype('category')\n\n# Handle missing values in target variable and convert to integer\ndf['Exited'] = df['Exited'].fillna(df['Exited'].mode()[0])\ndf['Exited'] = df['Exited'].astype(int)\n\n# Define columns\ncategorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\nnumerical_columns = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n\n# Apply Feature Hashing\nhasher = FeatureHasher(n_features=10, input_type='string')\nhashed_features = []\n\nfor col in categorical_columns:\n    # Convert to string and prepare data for hashing\n    col_data = [[str(val)] for val in df[col]]\n    # Apply hashing\n    hashed = hasher.transform(col_data).toarray()\n    hashed_features.append(hashed)\n\n# Combine all hashed features\nall_hashed = np.hstack(hashed_features)\n\n# Combine with numerical features\nnumerical_data = df[numerical_columns].values\nX = np.hstack([numerical_data, all_hashed])\ny = df['Exited'].values\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\ndef evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test, model_name):\n    # Train the model\n    model.fit(X_train_scaled, y_train)\n    \n    # Get predictions\n    train_pred = model.predict(X_train_scaled)\n    test_pred = model.predict(X_test_scaled)\n    \n    # Calculate accuracies\n    train_accuracy = accuracy_score(y_train, train_pred)\n    test_accuracy = accuracy_score(y_test, test_pred)\n    \n    print(f\"\\n{model_name} Results:\")\n    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n    print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n    print(\"\\nTest Set Classification Report:\")\n    print(classification_report(y_test, test_pred))\n    \n    return train_accuracy, test_accuracy\n\n# Initialize and evaluate models\nmodels = {\n    'SVM': SVC(kernel='rbf', random_state=42),\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n}\n\nresults = {\n    'Model': [],\n    'Training Accuracy': [],\n    'Testing Accuracy': []\n}\n\n# Train and evaluate each model\nfor name, model in models.items():\n    print(f\"\\nEvaluating {name}...\")\n    train_acc, test_acc = evaluate_model(model, X_train_scaled, X_test_scaled, \n                                       y_train, y_test, name)\n    \n    results['Model'].append(name)\n    results['Training Accuracy'].append(train_acc)\n    results['Testing Accuracy'].append(test_acc)\n\n# Create results DataFrame\nresults_df = pd.DataFrame(results)\nresults_df['Accuracy Difference'] = results_df['Training Accuracy'] - results_df['Testing Accuracy']\n\nprint(\"\\nFinal Results Summary:\")\nprint(results_df)\n\n# Save results\nresults_df.to_csv('feature_hashing_results.csv', index=False)\n\n# For Random Forest, we can also look at feature importance\nrf_model = models['Random Forest']\nfeature_names = (numerical_columns + \n                [f'hash_feature_{i}' for i in range(all_hashed.shape[1])])\nfeature_importance = pd.DataFrame({\n    'feature': feature_names,\n    'importance': rf_model.feature_importances_\n})\nfeature_importance = feature_importance.sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features:\")\nprint(feature_importance.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T12:51:43.429109Z","iopub.execute_input":"2024-12-03T12:51:43.429830Z","iopub.status.idle":"2024-12-03T13:38:49.182478Z","shell.execute_reply.started":"2024-12-03T12:51:43.429794Z","shell.execute_reply":"2024-12-03T13:38:49.181635Z"}},"outputs":[{"name":"stdout","text":"\nEvaluating SVM...\n\nSVM Results:\nTraining Accuracy: 0.9102\nTesting Accuracy: 0.9086\n\nTest Set Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.97      0.95     44639\n           1       0.85      0.63      0.72     10373\n\n    accuracy                           0.91     55012\n   macro avg       0.88      0.80      0.83     55012\nweighted avg       0.91      0.91      0.90     55012\n\n\nEvaluating Random Forest...\n\nRandom Forest Results:\nTraining Accuracy: 0.9996\nTesting Accuracy: 0.9105\n\nTest Set Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95     44639\n           1       0.82      0.67      0.74     10373\n\n    accuracy                           0.91     55012\n   macro avg       0.87      0.82      0.84     55012\nweighted avg       0.91      0.91      0.91     55012\n\n\nEvaluating Logistic Regression...\n\nLogistic Regression Results:\nTraining Accuracy: 0.8675\nTesting Accuracy: 0.8671\n\nTest Set Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92     44639\n           1       0.74      0.46      0.56     10373\n\n    accuracy                           0.87     55012\n   macro avg       0.81      0.71      0.74     55012\nweighted avg       0.86      0.87      0.85     55012\n\n\nFinal Results Summary:\n                 Model  Training Accuracy  Testing Accuracy  \\\n0                  SVM           0.910214          0.908620   \n1        Random Forest           0.999627          0.910529   \n2  Logistic Regression           0.867510          0.867120   \n\n   Accuracy Difference  \n0             0.001594  \n1             0.089099  \n2             0.000390  \n\nTop 10 Most Important Features:\n            feature  importance\n1               Age    0.284330\n4     NumOfProducts    0.164531\n5   EstimatedSalary    0.139351\n0       CreditScore    0.128280\n3           Balance    0.103370\n2            Tenure    0.056041\n40  hash_feature_34    0.029895\n43  hash_feature_37    0.026904\n7    hash_feature_1    0.026399\n22  hash_feature_16    0.012132\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load and preprocess data\ndf = pd.read_csv('/kaggle/input/complete-dataset/augmented_data.csv')\ndf = df.drop_duplicates()\n\ndef fill_missing_values(df):\n    # For numerical columns\n    numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n    for col in numerical_cols:\n        df[col] = df[col].fillna(df[col].mean())\n    \n    # For categorical columns (including HasCrCard and IsActiveMember)\n    categorical_cols = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n    for col in categorical_cols:\n        df[col] = df[col].fillna(df[col].mode()[0])\n        df[col] = df[col].astype('category')  # Convert to categorical\n    \n    return df\n\nprint(\"Original dataset size:\", len(df))\n\ndef process_and_train(data, sample_size):\n    # Subsample the data\n    df_sub = data.sample(frac=sample_size, random_state=42)\n    print(f\"Subsampled dataset size for {sample_size*100}% sample: {len(df_sub)}\")\n    \n    df_sub = fill_missing_values(df_sub)\n    \n    # Drop unnecessary columns\n    columns_to_drop = ['id', 'Surname', 'CustomerId']\n    df_sub = df_sub.drop(columns=columns_to_drop)\n    \n    # Handle target variable\n    df_sub['Exited'] = df_sub['Exited'].fillna(df_sub['Exited'].mode()[0])\n    df_sub['Exited'] = df_sub['Exited'].astype(int)\n    \n    # Label encode categorical variables\n    le = LabelEncoder()\n    categorical_columns = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']\n    for col in categorical_columns:\n        df_sub[col] = le.fit_transform(df_sub[col].astype(str))\n    \n    # Prepare features and target\n    X = df_sub.drop('Exited', axis=1)\n    y = df_sub['Exited']\n    \n    # Split and scale\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n    \n    return X_train_scaled, X_test_scaled, y_train, y_test, X.columns\n\ndef evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test, model_name):\n    model.fit(X_train_scaled, y_train)\n    train_pred = model.predict(X_train_scaled)\n    test_pred = model.predict(X_test_scaled)\n    \n    train_accuracy = accuracy_score(y_train, train_pred)\n    test_accuracy = accuracy_score(y_test, test_pred)\n    \n    print(f\"\\n{model_name} Results:\")\n    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n    print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, test_pred))\n    \n    return train_accuracy, test_accuracy\n\n# Test different sample sizes\nsubsample_sizes = [0.1, 0.3, 0.5]\nresults_by_size = []\n\nfor size in subsample_sizes:\n    print(f\"\\nProcessing {size*100}% of data\")\n    \n    X_train_scaled, X_test_scaled, y_train, y_test, feature_names = process_and_train(df, size)\n    \n    models = {\n        'SVM': SVC(kernel='rbf', random_state=42),\n        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n    }\n    \n    for model_name, model in models.items():\n        train_acc, test_acc = evaluate_model(\n            model, X_train_scaled, X_test_scaled, y_train, y_test, model_name\n        )\n        \n        results_by_size.append({\n            'Sample Size': f\"{size*100}%\",\n            'Model': model_name,\n            'Training Accuracy': train_acc,\n            'Testing Accuracy': test_acc,\n            'Accuracy Difference': train_acc - test_acc\n        })\n        \n        # For Random Forest, analyze feature importance\n        if model_name == 'Random Forest':\n            feature_importance = pd.DataFrame({\n                'feature': feature_names,\n                'importance': model.feature_importances_\n            })\n            feature_importance = feature_importance.sort_values('importance', ascending=False)\n            print(f\"\\nTop 10 Important Features for {size*100}% sample:\")\n            print(feature_importance.head(10))\n\n# Create final results DataFrame\nresults_df = pd.DataFrame(results_by_size)\n\n# Create pivot table for better visualization\npivot_results = results_df.pivot_table(\n    index='Model',\n    columns='Sample Size',\n    values=['Training Accuracy', 'Testing Accuracy', 'Accuracy Difference']\n)\n\nprint(\"\\nFinal Results Summary:\")\nprint(pivot_results)\n\n# Save results\nresults_df.to_csv('subsampling_results.csv', index=False)\npivot_results.to_csv('subsampling_results_pivot.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T13:43:57.305468Z","iopub.execute_input":"2024-12-03T13:43:57.305823Z","iopub.status.idle":"2024-12-03T13:51:25.350877Z","shell.execute_reply.started":"2024-12-03T13:43:57.305791Z","shell.execute_reply":"2024-12-03T13:51:25.349920Z"}},"outputs":[{"name":"stdout","text":"Original dataset size: 275058\n\nProcessing 10.0% of data\nSubsampled dataset size for 10.0% sample: 27506\n\nSVM Results:\nTraining Accuracy: 0.9062\nTesting Accuracy: 0.9042\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.98      0.94      4478\n           1       0.85      0.59      0.70      1024\n\n    accuracy                           0.90      5502\n   macro avg       0.88      0.78      0.82      5502\nweighted avg       0.90      0.90      0.90      5502\n\n\nRandom Forest Results:\nTraining Accuracy: 1.0000\nTesting Accuracy: 0.9091\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.97      0.95      4478\n           1       0.82      0.66      0.73      1024\n\n    accuracy                           0.91      5502\n   macro avg       0.87      0.81      0.84      5502\nweighted avg       0.91      0.91      0.91      5502\n\n\nTop 10 Important Features for 10.0% sample:\n           feature  importance\n3              Age    0.276783\n6    NumOfProducts    0.164268\n9  EstimatedSalary    0.128988\n0      CreditScore    0.120028\n5          Balance    0.103959\n4           Tenure    0.064941\n8   IsActiveMember    0.059983\n1        Geography    0.037173\n2           Gender    0.029122\n7        HasCrCard    0.014756\n\nLogistic Regression Results:\nTraining Accuracy: 0.8562\nTesting Accuracy: 0.8604\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.97      0.92      4478\n           1       0.74      0.39      0.51      1024\n\n    accuracy                           0.86      5502\n   macro avg       0.81      0.68      0.71      5502\nweighted avg       0.85      0.86      0.84      5502\n\n\nProcessing 30.0% of data\nSubsampled dataset size for 30.0% sample: 82517\n\nSVM Results:\nTraining Accuracy: 0.9096\nTesting Accuracy: 0.9108\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.98      0.95     13472\n           1       0.85      0.62      0.72      3032\n\n    accuracy                           0.91     16504\n   macro avg       0.89      0.80      0.83     16504\nweighted avg       0.91      0.91      0.91     16504\n\n\nRandom Forest Results:\nTraining Accuracy: 0.9999\nTesting Accuracy: 0.9117\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95     13472\n           1       0.82      0.67      0.74      3032\n\n    accuracy                           0.91     16504\n   macro avg       0.87      0.82      0.84     16504\nweighted avg       0.91      0.91      0.91     16504\n\n\nTop 10 Important Features for 30.0% sample:\n           feature  importance\n3              Age    0.280345\n6    NumOfProducts    0.174862\n9  EstimatedSalary    0.129528\n0      CreditScore    0.119002\n5          Balance    0.100293\n4           Tenure    0.060539\n8   IsActiveMember    0.059497\n1        Geography    0.039106\n2           Gender    0.024414\n7        HasCrCard    0.012414\n\nLogistic Regression Results:\nTraining Accuracy: 0.8556\nTesting Accuracy: 0.8598\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92     13472\n           1       0.71      0.40      0.51      3032\n\n    accuracy                           0.86     16504\n   macro avg       0.79      0.68      0.72     16504\nweighted avg       0.85      0.86      0.84     16504\n\n\nProcessing 50.0% of data\nSubsampled dataset size for 50.0% sample: 137529\n\nSVM Results:\nTraining Accuracy: 0.9101\nTesting Accuracy: 0.9105\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.92      0.98      0.95     22342\n           1       0.86      0.63      0.73      5164\n\n    accuracy                           0.91     27506\n   macro avg       0.89      0.80      0.84     27506\nweighted avg       0.91      0.91      0.90     27506\n\n\nRandom Forest Results:\nTraining Accuracy: 0.9998\nTesting Accuracy: 0.9129\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95     22342\n           1       0.83      0.67      0.74      5164\n\n    accuracy                           0.91     27506\n   macro avg       0.88      0.82      0.85     27506\nweighted avg       0.91      0.91      0.91     27506\n\n\nTop 10 Important Features for 50.0% sample:\n           feature  importance\n3              Age    0.278518\n6    NumOfProducts    0.172878\n9  EstimatedSalary    0.132278\n0      CreditScore    0.122234\n5          Balance    0.100297\n4           Tenure    0.060059\n8   IsActiveMember    0.060011\n1        Geography    0.039220\n2           Gender    0.023042\n7        HasCrCard    0.011463\n\nLogistic Regression Results:\nTraining Accuracy: 0.8564\nTesting Accuracy: 0.8586\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.87      0.96      0.92     22342\n           1       0.72      0.40      0.52      5164\n\n    accuracy                           0.86     27506\n   macro avg       0.80      0.68      0.72     27506\nweighted avg       0.85      0.86      0.84     27506\n\n\nFinal Results Summary:\n                    Accuracy Difference                     Testing Accuracy  \\\nSample Size                       10.0%     30.0%     50.0%            10.0%   \nModel                                                                          \nLogistic Regression           -0.004206 -0.004233 -0.002192         0.860414   \nRandom Forest                  0.090831  0.088145  0.086981         0.909124   \nSVM                            0.001937 -0.001170 -0.000473         0.904217   \n\n                                        Training Accuracy                      \nSample Size             30.0%     50.0%             10.0%     30.0%     50.0%  \nModel                                                                          \nLogistic Regression  0.859792  0.858613          0.856208  0.855559  0.856421  \nRandom Forest        0.911718  0.912855          0.999955  0.999864  0.999836  \nSVM                  0.910810  0.910529          0.906153  0.909639  0.910055  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}